{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018/2019 - Task List 10\n",
    "\n",
    "1. Implement Naive Bayes classifier with pyro\n",
    "    - create apropriate parameters (mean and std for a and b, sigma - noise)\n",
    "    - provide optimization procedure\n",
    "    - check appropriateness of implemented method with selected dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():    \n",
    "    data_seeds = pd.read_csv('./data_sets/seeds.data', sep=\"\\t\", header=None)\n",
    "    data_seeds.columns = [\"Area A\", \"Perimeter P\", \"Compactness C = 4*pi*A/P^2\", \"Length of kernel\",\n",
    "                      \"Width of kernel\", \"Asymmetry coefficient\", \"Length of kernel groove\", \"decision\"]\n",
    "    return data_seeds.iloc[:, :-1].get_values(), data_seeds.iloc[:, -1:].get_values()\n",
    "\n",
    "# assuming normal distributuion of continuous attributes, we can use pdf instead of discretization\n",
    "# def probability_density_function(mean, std, value):\n",
    "#     # shouldn't happen\n",
    "#     if std == 0:\n",
    "#         std = 0.001\n",
    "# #         return .001\n",
    "\n",
    "#     return 1 / (std * np.sqrt(2 * np.pi)) * np.exp(- (value - mean) ** 2 / (2 * std ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-80557f6e5c0f>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-80557f6e5c0f>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    a = pyro.sample(\"a\", dist.Normal(,[apriori])) # dim: 3x2 -> attr_num x decisions_num\u001b[0m\n\u001b[0m                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def pdf_normal(value, mean, std):\n",
    "    # shouldn't happen\n",
    "    if std == 0:\n",
    "        return .001\n",
    "\n",
    "    return 1 / (std * np.sqrt(2 * np.pi)) * np.exp(- (value - mean) ** 2 / (2 * std ** 2))\n",
    "\n",
    "def model(data_x, data_y):    \n",
    "#     abc = pyro.sample(\"abc\", dist.Beta(1, 1))\n",
    "    apriori = pyro.sample(\"apriori\", dist.Normal(torch.zeros(3, 2)))\n",
    "\n",
    "    # ask\n",
    "    # notation like this was on blackboard - what it suppose to mean?\n",
    "    apriori = dist.Normal(torch.zeros(3, 2)) # dim: attr_num x decisions_num\n",
    "    \n",
    "    # ask\n",
    "    # is this declaration ok?\n",
    "    # and how to get to those indexes in plate?\n",
    "    # dim: attr_num x decisions_num\n",
    "    apriori_mean = torch.zeros(attr_num, decisions_num[-1])\n",
    "    apriori_std = torch.zeros(attr_num, decisions_num[-1])\n",
    "    \n",
    "    # go throught decisions - unique data_y\n",
    "    with pyro.plate(\"decisions\", size=decisions_num):\n",
    "        # sample prob of class\n",
    "        # why wy sample class, while we are having it in plate?\n",
    "        # dim: 1x2 -> 1 x decisions_num\n",
    "        decision_prob = pyro.sample(\"decision\", dist.Categorical(decisions_wages))\n",
    "        \n",
    "        with pyro.plate(\"attributes\", size=attr_num) as value:\n",
    "            # sampling from whole apriori?\n",
    "            a = pyro.sample(\"a\", dist.Normal(,[apriori])) # dim: 3x2 -> attr_num x decisions_num\n",
    "            # ask\n",
    "            # how to get the value - just x_data?\n",
    "            pdf = pdf_normal(x_data, mean, std) # wym: n x 3 -> objects x attr_num\n",
    "            \n",
    "            pyro.sample(\"obs\", dist.Categorical(pdf), obs=y_data)\n",
    "\n",
    "def guide(data_x, data_y):\n",
    "    # todo\n",
    "    \n",
    "    # would it work?\n",
    "    pyro.param(\"\", mean, tensor.zeros(attr_num, decisions_num[-1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(data_x, data_y):\n",
    "    # some dimensions\n",
    "    count = len(data_x)\n",
    "    decisions_num = np.unique(data_y)\n",
    "    attr_num = len(data_x[0])\n",
    "    # todo change - modify it later in training\n",
    "    decisions_wages = torch.tensor([1/decisions_num[-1]] * decisions_num[-1])\n",
    "    \n",
    "    pyro.clear_param_store()\n",
    "    num_iterations = 3000\n",
    "#     model = create_probabilistic_model()\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.005})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=count)\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(data_x, data_y)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (model, svi)\n",
    "\n",
    "# def get_marginal(traces, sites):\n",
    "#     empirical_marginal=EmpiricalMarginal(traces, sites)\n",
    "#     return empirical_marginal._get_samples_and_weights()[0].detach().cpu().numpy()\n",
    "\n",
    "# def wrapped_model(x_data, y_data):\n",
    "#     model_result=probabilistic_model(x_data, y_data)\n",
    "#     pyro.sample(\"prediction\", pyro.distributions.Delta(model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, data_y = read_dataset()\n",
    "\n",
    "count = len(data_x)\n",
    "decisions_num = np.unique(data_y)\n",
    "attr_num = len(data_x[0])\n",
    "\n",
    "\n",
    "# print(decisions_num)\n",
    "# train(data_x, data_y)\n",
    "\n",
    "# check parameters\n",
    "# print(\"Check parameters:\")\n",
    "# for name, value in pyro.get_param_store().items():\n",
    "#     print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d7a0416997d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mwages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdecisions_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdecisions_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tmp\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mapriori\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_constraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# apriori = pyro.sample(\"apriori\", dist.Beta(1, 1))\n",
    "# abc = pyro.sample(\"abs\", dist.Normal(3, 2))\n",
    "\n",
    "# with pyro.plate(\"map\", size=2):\n",
    "#     # c=pyro.sample(\"\", Categorical(abc)) # wym: 1x2\n",
    "#     a=pyro.sample(\"\", dist.Normal([apriori])) # wym: 3x2\n",
    "#     pdf = PDF(x_data) # wym: n x 3\n",
    "\n",
    "#     pdf_c = abc * pdf # wym: n x 2\n",
    "\n",
    "#     tst = pyro.sample(dist.Categorical(pdf_c)) # nx2\n",
    "tst, tst_2 = read_dataset()\n",
    "# tmp = pyro.sample(\"tmp\", dist.Beta(1, 1))\n",
    "# torch.tensor([ 0.25, 0.25, 0.25, 0.25 ])\n",
    "# decisions_num = 5\n",
    "# wages = torch.ones(1, decisions_num[-1])*[1/decisions_num] #torch.tensor([1/decisions_num])*3\n",
    "wages = torch.tensor([1/decisions_num[-1]] * decisions_num[-1])\n",
    "tmp = pyro.sample(\"tmp\", dist.Categorical(wages))\n",
    "apriori = dist.Normal(0.3, 0.1, torch.zeros(3, 2))\n",
    "\n",
    "pyro.sample('tst', dist.Normal(torch.tensor.zeros([0]), torch.tensor(1)))\n",
    "# print(1/decisions_num[-1])\n",
    "print(apriori)\n",
    "print(tmp.size())\n",
    "print(tmp.squeeze(-1).size())\n",
    "# print(pyro.sample(\"tst\", dist.Categorical(tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attr = 10\n",
    "num_class = 3\n",
    "\n",
    "mu = pyro.sample('mu_attr', dist.Normal(torch.zeros([num_class, num_attr]), torch.ones([num_class, num_attr])))\n",
    "sigma = abs(pyro.sample('sigma_attr', dist.Normal(torch.zeros([num_class, num_attr]), torch.ones([num_class, num_attr]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    with pyro.plate(\"decisions\", size=decisions_num) as _:\n",
    "        \n",
    "        pyro.sampe('class', dist.Categorical(), obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(num_clas)\n",
    "    with pyro.plate(\"tst\", size=num_attr) as _:\n",
    "        print(pyro.sampe('class', dist.Normal()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista[lista=!lista]\n",
    "f\"std--{clazz}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5])\n",
      "tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "tensor([[[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "ten_a = torch.ones([3, 5])\n",
    "ten_b = torch.ones([3, 5])\n",
    "print(ten_a.size())\n",
    "print(ten_b)\n",
    "ten_stack = torch.stack([ten_a, ten_b], dim=0)\n",
    "print(ten_stack)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
