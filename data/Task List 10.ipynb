{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018/2019 - Task List 10\n",
    "\n",
    "1. Implement Naive Bayes classifier with pyro\n",
    "    - create apropriate parameters (mean and std for a and b, sigma - noise)\n",
    "    - provide optimization procedure\n",
    "    - check appropriateness of implemented method with selected dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():    \n",
    "    data_seeds = pd.read_csv('./data_sets/seeds.data', sep=\"\\t\", header=None)\n",
    "    data_seeds.columns = [\"Area A\", \"Perimeter P\", \"Compactness C = 4*pi*A/P^2\", \"Length of kernel\",\n",
    "                      \"Width of kernel\", \"Asymmetry coefficient\", \"Length of kernel groove\", \"decision\"]\n",
    "    return data_seeds\n",
    "\n",
    "def get_attributes_mi_sigma(data_set):\n",
    "    mean = data_seeds.mean(axis=0).tolist()[:-1]\n",
    "    std = data_seeds.std(axis=0).tolist()[:-1]\n",
    "    matrix = [[] for _ in range(len(mean))]\n",
    "\n",
    "    for idx in range(len(mean)):\n",
    "        # mean, std, sigma <- for every attribute in dataset\n",
    "        matrix[idx] = [idx, mean[idx], std[idx], pyro.sample(\"mean_\", dist.Uniform(0., 5.))]\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "# def init_attr_priors(data_set):\n",
    "\n",
    "# assuming normal distributuion of continuous attributes, we can use pdf instead of discretization\n",
    "def probability_density_function(mean, std, value):\n",
    "    # shouldn't happen\n",
    "    if std == 0:\n",
    "        std = 0.001\n",
    "#         return .001\n",
    "\n",
    "    return 1 / (std * np.sqrt(2 * np.pi)) * np.exp(- (value - mean) ** 2 / (2 * std ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.a = nn.Linear(1, 1, bias=False)\n",
    "        self.b = nn.Parameter(torch.tensor(1.))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # todo check it\n",
    "        return self.a(x) + self.b\n",
    "    \n",
    "def row_sampling(row, data_set):\n",
    "    noise = row[3]\n",
    "    label = \"mean_\" + str(row[0])\n",
    "    mean = pyro.sample(\"mean_\", dist.Normal(row[1], noise))\n",
    "    std = pyro.sample(\"std_\" + str(row[0]), dist.Normal(row[2], noise))\n",
    "    sigma = pyro.sample(\"sigma_\" + str(row[0]),  dist.Uniform(0., 5.))\n",
    "    return [mean, std, sigma]\n",
    "    \n",
    "def create_probabilistic_model():\n",
    "    regression_model=RegressionModel()\n",
    "    def probabilistic_model(data_set):\n",
    "        priors_pd = pd.DataFrame(data=priors, columns=[\"idx\", \"mean\", \"std\", \"noise\"])\n",
    "    \n",
    "    # todo check if it work proper\n",
    "    # if not - work around could be adding new values to new tmp columns\n",
    "    # then move value from tmp to original and delete tmp\n",
    "    priors_pd[[\"mean\", \"std\", \"noise\"]] = priors_pd.apply(\n",
    "        lambda row: pd.Series(row_sampling(row, data_seeds)), axis=1\n",
    "    )\n",
    "        \n",
    "#         a = pyro.sample(\"a\", dist.Normal(8., 1000.))\n",
    "#         b_a = pyro.sample(\"bA\", dist.Normal(0., 1.))\n",
    "#         sigma = pyro.sample(\"sigma\",  dist.Uniform(0., 10.))        \n",
    "    \n",
    "    with pyro.plate(\"map\", len(x_data)):\n",
    "#             todo update matrix\n",
    "        pyro.sample(\"obs\", matrix, obs=y_data)\n",
    "        return mean\n",
    "    return probabilistic_model\n",
    "\n",
    "def guide(attributes_mi_sigma):\n",
    "#     a_loc = pyro.param('w_loc', torch.tensor(0.))\n",
    "#     a_scale = pyro.param('w_scale', torch.tensor(1.),\n",
    "#                         constraint=constraints.positive)\n",
    "#     b_loc = pyro.param('b_loc', torch.tensor(0.))\n",
    "#     b_scale = pyro.param('b_scale', torch.tensor(1.),\n",
    "#                         constraint=constraints.positive)  \n",
    "#     sigma_loc = pyro.param('sigma_loc', torch.tensor(1.),\n",
    "#                              constraint=constraints.positive)\n",
    "    \n",
    "#     a = pyro.sample(\"a\", dist.Normal(a_loc, a_scale))\n",
    "#     b_a = pyro.sample(\"bA\", dist.Normal(b_loc, b_scale))\n",
    "#     sigma = pyro.sample(\"sigma\", dist.Normal(sigma_loc, torch.tensor(0.05)))\n",
    "    mean = a * x_data + b_a\n",
    "\n",
    "\n",
    "def train():\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations = 3000 #8000\n",
    "    model = create_probabilistic_model()\n",
    "#     guide = AutoDiagonalNormal(model)\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.005})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=count)\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(mcg_data, gvh_data)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (model, svi)\n",
    "\n",
    "# def get_marginal(traces, sites):\n",
    "#     empirical_marginal=EmpiricalMarginal(traces, sites)\n",
    "#     return empirical_marginal._get_samples_and_weights()[0].detach().cpu().numpy()\n",
    "\n",
    "# def summary(traces, sites):\n",
    "#     marginal = get_marginal(traces, sites)\n",
    "#     site_stats = {}\n",
    "#     for i in range(marginal.shape[1]):\n",
    "#         site_name = sites[i]\n",
    "#         site_marginal=marginal[:, i]\n",
    "#         marginal_site = pd.DataFrame(site_marginal).transpose()\n",
    "#         describe = partial(pd.Series.describe, percentiles=[.05, 0.25, 0.5, 0.75, 0.95])\n",
    "#         site_stats[site_name] = marginal_site.apply(describe, axis=1) \\\n",
    "#             [[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "#     return site_stats\n",
    "\n",
    "# def wrapped_model(x_data, y_data):\n",
    "#     model_result=probabilistic_model(x_data, y_data)\n",
    "#     pyro.sample(\"prediction\", pyro.distributions.Delta(model_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "   idx       mean       std           noise\n",
      "0    0  14.847524  2.909699  tensor(3.7882)\n",
      "1    1  14.559286  1.305959  tensor(1.3966)\n",
      "2    2   0.870999  0.023629  tensor(2.0153)\n",
      "3    3   5.628533  0.443063  tensor(3.6734)\n",
      "4    4   3.258605  0.377714  tensor(0.1464)\n",
      "5    5   3.700201  1.503557  tensor(3.9993)\n",
      "6    6   5.408071  0.491480  tensor(1.9857)\n",
      "   idx             mean             std           noise\n",
      "0    0   tensor(9.0790)  tensor(4.3556)  tensor(2.8624)\n",
      "1    1  tensor(15.6004)  tensor(1.2011)  tensor(0.9901)\n",
      "2    2  tensor(-0.6661)  tensor(2.8390)  tensor(3.9903)\n",
      "3    3   tensor(7.5549)  tensor(4.1741)  tensor(4.8714)\n",
      "4    4   tensor(3.1969)  tensor(0.3029)  tensor(4.6953)\n",
      "5    5   tensor(2.5924)  tensor(3.4115)  tensor(1.4423)\n",
      "6    6   tensor(9.6038)  tensor(0.4836)  tensor(1.1729)\n"
     ]
    }
   ],
   "source": [
    "data_seeds = read_dataset()\n",
    "count = len(data_seeds)\n",
    "priors = get_attributes_mi_sigma(data_set=data_seeds)\n",
    "priors_pd = pd.DataFrame(data=priors, columns=[\"idx\", \"mean\", \"std\", \"noise\"])\n",
    "print(priors_pd.iloc[0][0])\n",
    "# priors_pd[[\"mean\", \"std\", \"noise\"]]\n",
    "\n",
    "print(priors_pd)\n",
    "priors_pd[[\"mean\", \"std\", \"noise\"]] = priors_pd.apply(\n",
    "    lambda row: pd.Series(row_sampling(row, data_seeds)), axis=1\n",
    ")\n",
    "print(priors_pd)\n",
    "# tst = \"mean_\" + str(priors_pd.iloc[0][0])\n",
    "# print(type(tst))\n",
    "# print(type(priors_pd.iloc[0][3]))\n",
    "# dist.Normal(3, 0.01)\n",
    "# tst = pyro.sample(\"mean_\", dist.Uniform(0., 5.))\n",
    "# print(tst)\n",
    "# row_sampling(priors_pd.iloc[0], data_seeds)\n",
    "\n",
    "# check parameters\n",
    "# print(\"Check parameters:\")\n",
    "# for name, value in pyro.get_param_store().items():\n",
    "#     print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac56ead6d10a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# c=pyro.sample(\"\", Categorical(abc)) # wym: 1x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpyro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapriori\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# wym: 3x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# wym: n x 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'scale'"
     ]
    }
   ],
   "source": [
    "apriori = pyro.sample(\"apriori\", dist.Beta(1, 1))\n",
    "abc = pyro.sample(\"abs\", dist.Normal(3, 2))\n",
    "\n",
    "with pyro.plate(\"map\", size=2):\n",
    "    # c=pyro.sample(\"\", Categorical(abc)) # wym: 1x2\n",
    "    a=pyro.sample(\"\", dist.Normal([apriori])) # wym: 3x2\n",
    "    pdf = PDF(x_data) # wym: n x 3\n",
    "\n",
    "    pdf_c = abc * pdf # wym: n x 2\n",
    "\n",
    "    tst = pyro.sample(dist.Categorical(pdf_c)) # nx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
